{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f90c7d10",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/temp_folder/server_config.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#サーバーコントロールファイル\u001b[39;00m\n\u001b[1;32m      2\u001b[0m server_config_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/temp_folder/server_config.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mserver_config_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      4\u001b[0m     file_content \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      5\u001b[0m exec(file_content)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-プライマルホールディングス株式会社/PassageDrive/Workspace/Documents/gfinder-data-tools/gfdatatool/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/temp_folder/server_config.txt'"
     ]
    }
   ],
   "source": [
    "#サーバーコントロールファイル\n",
    "server_config_path = 'C:/temp_folder/server_config.txt'\n",
    "with open(server_config_path, 'r', encoding='utf-8') as file:\n",
    "    file_content = file.read()\n",
    "exec(file_content)\n",
    "\n",
    "print('Server Message:', server_message)\n",
    "print('Server Names:', server_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b685e4c6",
   "metadata": {},
   "source": [
    "## 0.設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4e62c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.1.ライブラリの導入\n",
    "import pandas as pd\n",
    "import os,glob\n",
    "import requests\n",
    "import time,random\n",
    "from datetime import datetime, timedelta\n",
    "import traceback\n",
    "\n",
    "#全ての列を表示する\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# 忽略 InsecureRequestWarning 警告\n",
    "import requests\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "import urllib3\n",
    "urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "#PDFテキスト抽出関連\n",
    "import pdfplumber\n",
    "\n",
    "#PDF画像変換関連\n",
    "from pdf2image import convert_from_path\n",
    "def convert_to_pic_2000(input_pdf_path, output_pic_dirpath):\n",
    "    #https://pdf2image.readthedocs.io/en/latest/reference.html\n",
    "    #popplerの保存フォルダをpoppler_pathで指定する\n",
    "    # make dirs\n",
    "    if not os.path.exists(output_pic_dirpath):\n",
    "        os.makedirs(output_pic_dirpath)\n",
    "    #open pdf-file\n",
    "    images = convert_from_path(input_pdf_path, poppler_path = r\"/opt/homebrew/bin\",size=2000)\n",
    "    #save every pages\n",
    "    for image in images:\n",
    "        output_pic_filepath = os.path.join(output_pic_dirpath, str(images.index(image)+1)+'_original.jpg')\n",
    "        image.save(output_pic_filepath, 'JPEG')\n",
    "        \n",
    "def convert_to_pic_500(input_pdf_path, output_pic_dirpath):\n",
    "    #https://pdf2image.readthedocs.io/en/latest/reference.html\n",
    "    #popplerの保存フォルダをpoppler_pathで指定する\n",
    "    # make dirs\n",
    "    if not os.path.exists(output_pic_dirpath):\n",
    "        os.makedirs(output_pic_dirpath)\n",
    "    #open pdf-file\n",
    "    images = convert_from_path(input_pdf_path, poppler_path = r\"/opt/homebrew/bin\", size=500)\n",
    "    #save every pages\n",
    "    for image in images:\n",
    "        output_pic_filepath = os.path.join(output_pic_dirpath, str(images.index(image)+1)+'.jpg')\n",
    "        image.save(output_pic_filepath, 'JPEG')\n",
    "\n",
    "# =======================\n",
    "# 2. 追加：指定ページだけを画像化する関数（新規）\n",
    "# =======================\n",
    "# def convert_to_pic_500_for_page(input_pdf_path, output_pic_dirpath, page_number):\n",
    "#     \"\"\"\n",
    "#     指定したPDFファイルの特定のpage_number(1始まり)のみを\n",
    "#     解像度size=500で画像化し、JPEGファイルとして保存する。\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(output_pic_dirpath):\n",
    "#         os.makedirs(output_pic_dirpath)\n",
    "#     # pdf2imageの first_page, last_page を使って特定ページのみ画像化\n",
    "#     images = convert_from_path(\n",
    "#         input_pdf_path,\n",
    "#         poppler_path=r\"/opt/homebrew/bin\",\n",
    "#         size=500,\n",
    "#         first_page=page_number,\n",
    "#         last_page=page_number\n",
    "#     )\n",
    "#     # 原則1枚だけ返る想定だが、念のためループ\n",
    "#     for idx, image in enumerate(images):\n",
    "#         output_pic_filepath = os.path.join(output_pic_dirpath, f\"p{page_number}_{idx+1}.jpg\")\n",
    "        # image.save(output_pic_filepath, 'JPEG')\n",
    "\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "POPPLER_PATH = \"/opt/homebrew/bin\"\n",
    "\n",
    "def get_page_image_in_memory(pdf_path, page_number, poppler_path=POPPLER_PATH, size=1000):\n",
    "    \"\"\"\n",
    "    指定したPDFファイルの特定のpage_number(1始まり)を\n",
    "    解像度size=500で画像化し、PIL.Imageオブジェクトのリストとして返す。\n",
    "    \"\"\"\n",
    "    images = convert_from_path(\n",
    "        pdf_path,\n",
    "        poppler_path=poppler_path,\n",
    "        size=size,\n",
    "        first_page=page_number,\n",
    "        last_page=page_number\n",
    "    )\n",
    "    return images  # [PIL.Image, ...]\n",
    "\n",
    "\n",
    "#GCPへのアップロード関連\n",
    "#!pip install --upgrade google-cloud-storage\n",
    "from google.cloud import storage\n",
    "bucket_name_prod='gf-p'\n",
    "service_account_path_prod='../config/gcp_auth/g-finder-prod-9a658eb38e6c.json'\n",
    "bucket_name_backup='backup-prod-cs'\n",
    "service_account_path_backup='../config/gcp_auth/glocal-backup-392107-0320e3f6fb57.json'\n",
    "\n",
    "#0.2,取り込みファイルのパス指定\n",
    "#0.2.1.Teams保管ファイル　親パス\n",
    "path_teams='/Users/takenaka/Library/CloudStorage/OneDrive-共有ライブラリ-プライマルホールディングス株式会社/G-Finder - G-Finder関係資料 - G-Finder関係資料/00_取り込み用/'\n",
    "#0.2.1.1.書類提出フォルダ（本番）\n",
    "path_teams_inputdata_folder=\"00_文書インプットデータ/開発_竹中/\"\n",
    "#0.2.1.2.省庁・自治体の団体コード付与ルールを記載する資料\n",
    "path_teams_code='01_基礎データ/省庁・自治体基礎データ.xlsx'\n",
    "#0.2.1.3.カテゴリーIDの付与ルール を記載する資料\n",
    "path_teams_category=\"01_基礎データ/インデックスカテゴリールール.xlsx\"\n",
    "#0.2.1.4.解析結果レポートのフォルダ（本番）\n",
    "path_teams_report_folder=\"02_解析結果レポート/本番_解析結果/\"\n",
    "\n",
    "#0.2.2.OneDrive保管ファイル　親パス\n",
    "#path_onedrive=\"C:/Users/Administrator/OneDrive - プライマルホールディングス株式会社/CloudDesktop/ElasticDataUpload/\"\n",
    "#0.2.2.1. CSVなどのファイルを保存するローカルフォルダ\n",
    "local_save_folder='/Users/takenaka/Library/CloudStorage/OneDrive-プライマルホールディングス株式会社/PassageDrive/Workspace/Documents/gfinder-data-tools/config/bunsyo/'\n",
    "#0.2.2.2. 前回までの解析場所を記載する資料\n",
    "last_submit_id_folder='/Users/takenaka/Library/CloudStorage/OneDrive-プライマルホールディングス株式会社/PassageDrive/Workspace/Documents/gfinder-data-tools/config/last_submit/'\n",
    "\n",
    "#0.2.3. GCPアップ予定のPDFと画像などを一時保存するための臨時フォルダー\n",
    "temp_folder='/Users/takenaka/Library/CloudStorage/OneDrive-プライマルホールディングス株式会社/PassageDrive/Workspace/Documents/gfinder-data-tools/config/temp_folder/'\n",
    "\n",
    "#0.3.取り込み\n",
    "#0.3.1.Configファイルをローディング（省庁・自治体基礎データ）\n",
    "def format_code(row):\n",
    "    code=row['code']\n",
    "    if code==\"\":\n",
    "        pass\n",
    "    elif row['affiliation_name']=='省庁':\n",
    "        return str(int(code)).zfill(5)\n",
    "    else:\n",
    "        return str(int(code)).zfill(6)\n",
    "df_config_code1=pd.read_excel(path_teams+path_teams_code,sheet_name=\"自治体基礎データ\").fillna(\"\")\n",
    "df_config_code1=df_config_code1[[\"団体コード\",\"都道府県名\",\"市区町村名\"]].rename(columns={\"団体コード\":\"code\",\"都道府県名\":\"affiliation_name\",\"市区町村名\":\"organization_name\"})\n",
    "df_config_code2=pd.read_excel(path_teams+path_teams_code,sheet_name=\"省庁基礎データ\").fillna(\"\")\n",
    "df_config_code2=df_config_code2[[\"団体コード\",\"機関名称\"]].rename(columns={\"団体コード\":\"code\",\"機関名称\":\"organization_name\"})\n",
    "df_config_code2[\"affiliation_name\"]=\"省庁\"\n",
    "#...df_config_code=df_config_code1.append(df_config_code2)\n",
    "df_config_code = pd.concat([df_config_code1, df_config_code2], ignore_index=True)\n",
    "df_config_code['code'] = df_config_code.apply(format_code, axis=1)\n",
    "\n",
    "#0.3.2.Configファイルをローディング（カテゴリーID基礎データ）\n",
    "df_config_category=pd.read_excel(path_teams+path_teams_category,sheet_name=\"category\").fillna(\"\")\n",
    "df_config_subcategory=pd.read_excel(path_teams+path_teams_category,sheet_name=\"sub_category\").fillna(\"\")\n",
    "\n",
    "#0.3.3.前回までの解析場所を記載する資料をローディング\n",
    "# last_submit_id_folder='../config/last_submit/'\n",
    "# last_submit_id_files = glob.glob(last_submit_id_folder + \"*.csv\") \n",
    "# last_submit_id_tables=pd.concat((pd.read_csv(file) for file in last_submit_id_files), ignore_index=True)\n",
    "# #0.3.3.1.過去解析結果から、前回submit_idを獲得\n",
    "# last_submit_id_table=last_submit_id_tables[last_submit_id_tables['server_name'].isin(server_names)]\n",
    "#0.3.3.2.辞書化　サンプル{'Mercury': 0, 'Venus': 0}\n",
    "# last_submit_id_dict =last_submit_id_table.set_index('server_name')['submit_id'].to_dict()\n",
    "# for server_name in server_names:\n",
    "#     if server_name not in last_submit_id_dict:\n",
    "#         last_submit_id_dict[server_name] = 0\n",
    "\n",
    "#0.4.mecab関連\n",
    "import sys,MeCab,collections,math,re\n",
    "\n",
    "'''\n",
    "mecabrc: (デフォルト)\n",
    "-Ochasen: (ChaSen 互換形式)\n",
    "-Owakati: (分かち書きのみを出力)\n",
    "-Oyomi: (読みのみを出力)\n",
    "\n",
    "WindowsでPythonでMeCab（mecab-ipadic-NEologd） - Qiita\n",
    "https://qiita.com/yakipudding/items/0372dc79bb5722fa4b8b\n",
    "\"-d ..\\dic\\ipadic-neologd\" neologd搭載\n",
    "'''\n",
    "\n",
    "def calculate_digit_ratio(word: str) -> float:\n",
    "    #ワードの中の数字の％を算出\n",
    "    digit_chars = len(re.findall(r\"\\d\", word))\n",
    "    total_chars = len(word)\n",
    "    ratio = digit_chars / total_chars if total_chars > 0 else 0\n",
    "    return ratio\n",
    "\n",
    "def mecab_list(text):\n",
    "    #https://qiita.com/menon/items/2b5ad487a98882289567\n",
    "    tagger = MeCab.Tagger(\"-r /opt/homebrew/etc/mecabrc -d /opt/homebrew/lib/mecab/dic/ipadic\")\n",
    "    tagger.parse('')\n",
    "    node = tagger.parseToNode(text)\n",
    "    word_class = []\n",
    "    while node:\n",
    "        word = node.surface\n",
    "        wclass = node.feature.split(',')\n",
    "        if wclass[1] in [\"一般\",\"固有名詞\"]: #フィルタリング2列目\n",
    "        #if wclass[1] in [\"形容動詞語幹\",\"サ変接続\",\"一般\",\"固有名詞\",\"ナイ形容詞語幹\"]:\n",
    "        #if wclass[0] != u'BOS/EOS':\n",
    "            if wclass[0] in [\"副詞\",\"記号\"]: #フィルタリング1列目\n",
    "                pass\n",
    "            elif wclass[6] == \"*\": #辞書型がないとき\n",
    "                if len(word)<=1: #長さ＜１の単語を捨てる\n",
    "                    pass\n",
    "                elif word[0]==word[1]: #目次記号「・・・」などを捨てる\n",
    "                    pass\n",
    "                elif calculate_digit_ratio(word)>0.2: #「4月」など数字を含む無意味な頻出語を捨てる\n",
    "                    pass\n",
    "                else:\n",
    "                    #word_class.append((word,wclass[0],wclass[1],wclass[5],\"\"))\n",
    "                    word_class.append(word) #単語のみアウトプット\n",
    "            else: #辞書型があるとき\n",
    "                if len(wclass[6])<=1: #長さ＜１の単語を捨てる\n",
    "                    pass\n",
    "                elif calculate_digit_ratio(wclass[6])>0.2: #「4月」など数字を含む無意味な頻出語を捨てる\n",
    "                    pass\n",
    "                else:\n",
    "                    #word_class.append((word,wclass[0],wclass[1],wclass[4],wclass[5],wclass[6]))\n",
    "                    word_class.append(wclass[6])\n",
    "        node = node.next\n",
    "    return word_class\n",
    "\n",
    "#0.5. Elestic API\n",
    "from elasticsearch import Elasticsearch\n",
    "elastic_password_path='../config/Elastic_auth/password'\n",
    "\n",
    "#0.6 チェック機構\n",
    "# gfinder-data-tools のパスを追加\n",
    "current_dir = os.getcwd()  # Notebook起動時のディレクトリ\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, \"../config/gfinder-data-tools\"))\n",
    "sys.path.append(parent_dir)\n",
    "import DataValidator.LocalGovDataValidator.LocalGovDataValidator as LGDValidator\n",
    "import importlib\n",
    "importlib.reload(LGDValidator)\n",
    "\n",
    "#0.7 twilio\n",
    "# from twilio.rest import Client\n",
    "# twilio_password_path='../config/twilio_auth/password'\n",
    "\n",
    "# with open(twilio_password_path, 'r') as file:\n",
    "#     text_content = file.read()\n",
    "\n",
    "# twilio_variables = {}\n",
    "# for line in text_content.splitlines():\n",
    "#     line = line.strip()\n",
    "#     if line:  # 确保行不为空\n",
    "#         exec(line, twilio_variables)\n",
    "\n",
    "# def send_twilio_message(variables, message_body):\n",
    "#     try:\n",
    "#         account_sid = variables['account_sid']\n",
    "#         auth_token = variables['auth_token']\n",
    "#         from_number = variables['from_']\n",
    "#         to_number = variables['to']\n",
    "        \n",
    "#         client = Client(account_sid, auth_token)\n",
    "#         message = client.messages.create(\n",
    "#           from_=from_number,\n",
    "#           body=message_body,\n",
    "#           to=to_number\n",
    "#         )\n",
    "#         return message.sid\n",
    "#     except Exception as e:\n",
    "#         print(f\"TwillioError: {e}\")\n",
    "#         return None\n",
    "\n",
    "#0.8 ハッシュ値\n",
    "import hashlib\n",
    "def calculate_sha256(file_path):\n",
    "    sha256_hash = hashlib.sha256()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for byte_block in iter(lambda: f.read(4096), b\"\"):\n",
    "            sha256_hash.update(byte_block)\n",
    "    return sha256_hash.hexdigest()\n",
    "\n",
    "# Gemini OCR用\n",
    "import google.generativeai as genai\n",
    "import PIL.Image\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from google.generativeai.types.content_types import to_contents\n",
    "\n",
    "# =======================\n",
    "# 3. Gemini初期設定\n",
    "# =======================\n",
    "_ = load_dotenv(find_dotenv())\n",
    "genai.configure()  # .env内のGOOGLE_API_KEYを読み込む想定\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "def gemini_ocr_image(pil_image, prompt=\"画像から必ず全てのテキストを抽出して、抽出したテキストは必ず***と***で挟んでください。\"):\n",
    "    \"\"\"\n",
    "    PIL.ImageオブジェクトをGeminiへ渡し、OCR実行して返却されたテキストを返す。\n",
    "    \"\"\"\n",
    "    response = model.generate_content([pil_image, prompt])\n",
    "    return response.text\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_inside_asterisks(text):\n",
    "    \"\"\"\n",
    "    OCR結果のテキストから、\"*** ... ***\" で囲まれた部分をすべて抽出し、半角スペースで連結して返す。\n",
    "    もしマッチしなければ、空文字列を返す。\n",
    "    \"\"\"\n",
    "    matches = re.findall(r'\\*\\*\\*(.*?)\\*\\*\\*', text, flags=re.DOTALL)\n",
    "    extracted = ' '.join(match.strip() for match in matches if match.strip())\n",
    "    return extracted\n",
    "\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "def gemini_ocr_with_backoff(pil_img, prompt, max_retries=5, initial_delay=5):\n",
    "    \"\"\"\n",
    "    Gemini OCR API へのリクエストに対して、指数バックオフを実装。\n",
    "    \n",
    "    Args:\n",
    "        pil_img: OCR対象のPIL.Imageオブジェクト\n",
    "        prompt: OCRに対するプロンプト文字列\n",
    "        max_retries: 最大リトライ回数（デフォルト: 5）\n",
    "        initial_delay: 初回待機秒数（デフォルト: 5秒）\n",
    "        \n",
    "    Returns:\n",
    "        gemini_ocr_image の結果テキスト（成功した場合）\n",
    "        \n",
    "    Raises:\n",
    "        最終的な例外をそのまま再送出します。\n",
    "    \"\"\"\n",
    "    delay = initial_delay\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            # OCRリクエスト実行\n",
    "            ocr_text = gemini_ocr_image(pil_img, prompt=prompt)\n",
    "            return ocr_text\n",
    "        except Exception as e:\n",
    "            attempt += 1\n",
    "            print(f\"[OCRリトライ] 試行{attempt}/{max_retries}でエラー: {repr(e)}\")\n",
    "            print(traceback.format_exc())\n",
    "            if attempt >= max_retries:\n",
    "                raise\n",
    "            # 待機してからリトライ\n",
    "            time.sleep(delay)\n",
    "            delay *= 2  # 待機時間を倍にする\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df3ef5f",
   "metadata": {},
   "source": [
    "## 1-3.解析対象ファイル選定、データ整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fbf4a7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-24 15:29:24  INPUTDATA Excelローディング完了\n",
      "■Excelローディング：\n"
     ]
    }
   ],
   "source": [
    "#1.INPUTDATAをローディング\n",
    "#1.1.対象フォルダ内のExcelを読み取って合体する\n",
    "inpudata_files = glob.glob(path_teams+path_teams_inputdata_folder + \"*竹中.xlsx\") \n",
    "inputdata=pd.concat((pd.read_excel(file) for file in inpudata_files), ignore_index=True)\n",
    "\n",
    "#1.2.file_id列に値が存在する行のみを抽出する\n",
    "inputdata=inputdata[~inputdata.file_id.isna()].fillna(\"\")\n",
    "\n",
    "#1.3.該当サーバーの解析対象行を取得\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'),' INPUTDATA Excelローディング完了')\n",
    "# print('■現在のサーバー：'+\",\".join(server_names))\n",
    "print('■Excelローディング：')\n",
    "# print(inputdata.groupby('server_name')['file_id'].count())\n",
    "# inputdata=inputdata[inputdata['server_name'].isin(server_names)]\n",
    "\n",
    "# 1.4. 未解析の行を取得し、さらに submit_id が最も小さい行を取得\n",
    "# def filter_next_unprocessed(inputdata, last_submit_id_dict):\n",
    "#     # 各 server_name の最後に解析された submit_id より大きいすべてのレコードをフィルタリング\n",
    "#     # filtered_data = inputdata[inputdata.apply(lambda row: row['submit_id'] > last_submit_id_dict.get(row['server_name'], -1), axis=1)].copy()\n",
    "    \n",
    "#     # # 各 server_name の次の未解析の最小 submit_id を計算\n",
    "#     # min_submit_id_by_server = filtered_data.groupby('server_name')['submit_id'].transform('min')\n",
    "    \n",
    "#     # .loc を使用して、元の DataFrame に変更を加える\n",
    "#     filtered_data.loc[:, 'min_submit_id_for_server'] = min_submit_id_by_server\n",
    "    \n",
    "#     # グローバル最小の submit_id を見つける\n",
    "#     global_min_submit_id = min_submit_id_by_server.min()\n",
    "    \n",
    "#     # グローバル最小 submit_id のレコードをフィルタリング\n",
    "#     updated_inputdata = filtered_data[filtered_data['submit_id'] == global_min_submit_id].drop(columns=['min_submit_id_for_server'])\n",
    "    \n",
    "#     # 更新後の inputdata を返す\n",
    "#     return updated_inputdata\n",
    "\n",
    "# inputdata = filter_next_unprocessed(inputdata, last_submit_id_dict)\n",
    "# inputdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a017892f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-24 15:29:32  INPUTDATA構成完了\n",
      "カテゴリID付与失敗数： 0\n",
      "サブカテゴリーID付与失敗数： 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pq/jj6vyqq119j3qpdg8q0j3p740000gp/T/ipykernel_22463/3192950156.py:85: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  inputdata['重複チェック'].where(~inputdata.duplicated(subset=['source_url', 'category', 'sub_category'], keep='first'), 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "category_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sub_category",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sub_category_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "file_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "number_of_pages",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "affiliation_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "affiliation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "organization_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "organization",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fiscal_year_start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fiscal_year_end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "source_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "collected_at",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "modified_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submit_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "server_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "重複チェック",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "URL判定",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DL判定",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DLエラー詳細",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "画像化",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "画像化エラー詳細",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "テキスト解析",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "解析エラー詳細",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "OCR解析",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "OCRエラー詳細",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GCP格納",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GCPエラー詳細",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "画像格納",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "画像格納エラー詳細",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Elastic格納",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Elasticエラー詳細",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "34f03709-cff0-42ac-aa23-7c7081f170af",
       "rows": [
        [
         "0",
         "小谷村第６次総合計画",
         "4",
         "（自治体）予算",
         "6",
         "（自治体）補正予算",
         "AA0163873",
         "-",
         "001010",
         "00",
         "長野県",
         "1010",
         "小谷村",
         "2024",
         "2024",
         "https://www.vill.otari.nagano.jp/www/contents/1609976595002/files/6_sougou_web.pdf#page=45",
         "2024-09-06 11:24:00",
         "",
         "202502131",
         "Venus",
         "0",
         "-",
         "-",
         "-",
         "-",
         "-",
         "-",
         "-",
         "-",
         "-",
         "-",
         "-",
         "-",
         "-",
         "-",
         "-"
        ]
       ],
       "shape": {
        "columns": 35,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>sub_category_name</th>\n",
       "      <th>file_id</th>\n",
       "      <th>number_of_pages</th>\n",
       "      <th>code</th>\n",
       "      <th>affiliation_code</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>organization_code</th>\n",
       "      <th>organization</th>\n",
       "      <th>fiscal_year_start</th>\n",
       "      <th>fiscal_year_end</th>\n",
       "      <th>source_url</th>\n",
       "      <th>collected_at</th>\n",
       "      <th>modified_at</th>\n",
       "      <th>submit_id</th>\n",
       "      <th>server_name</th>\n",
       "      <th>重複チェック</th>\n",
       "      <th>URL判定</th>\n",
       "      <th>DL判定</th>\n",
       "      <th>DLエラー詳細</th>\n",
       "      <th>画像化</th>\n",
       "      <th>画像化エラー詳細</th>\n",
       "      <th>テキスト解析</th>\n",
       "      <th>解析エラー詳細</th>\n",
       "      <th>OCR解析</th>\n",
       "      <th>OCRエラー詳細</th>\n",
       "      <th>GCP格納</th>\n",
       "      <th>GCPエラー詳細</th>\n",
       "      <th>画像格納</th>\n",
       "      <th>画像格納エラー詳細</th>\n",
       "      <th>Elastic格納</th>\n",
       "      <th>Elasticエラー詳細</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>小谷村第６次総合計画</td>\n",
       "      <td>4</td>\n",
       "      <td>（自治体）予算</td>\n",
       "      <td>6</td>\n",
       "      <td>（自治体）補正予算</td>\n",
       "      <td>AA0163873</td>\n",
       "      <td>-</td>\n",
       "      <td>001010</td>\n",
       "      <td>00</td>\n",
       "      <td>長野県</td>\n",
       "      <td>1010</td>\n",
       "      <td>小谷村</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.vill.otari.nagano.jp/www/contents/...</td>\n",
       "      <td>2024-09-06 11:24:00</td>\n",
       "      <td></td>\n",
       "      <td>202502131</td>\n",
       "      <td>Venus</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        title  category category_name  sub_category sub_category_name  \\\n",
       "0  小谷村第６次総合計画         4       （自治体）予算             6         （自治体）補正予算   \n",
       "\n",
       "     file_id number_of_pages    code affiliation_code affiliation  \\\n",
       "0  AA0163873               -  001010               00         長野県   \n",
       "\n",
       "  organization_code organization  fiscal_year_start  fiscal_year_end  \\\n",
       "0              1010          小谷村               2024             2024   \n",
       "\n",
       "                                          source_url        collected_at  \\\n",
       "0  https://www.vill.otari.nagano.jp/www/contents/... 2024-09-06 11:24:00   \n",
       "\n",
       "  modified_at  submit_id server_name  重複チェック URL判定 DL判定 DLエラー詳細 画像化 画像化エラー詳細  \\\n",
       "0              202502131       Venus       0     -    -       -   -        -   \n",
       "\n",
       "  テキスト解析 解析エラー詳細 OCR解析 OCRエラー詳細 GCP格納 GCPエラー詳細 画像格納 画像格納エラー詳細 Elastic格納  \\\n",
       "0      -       -     -        -     -        -    -         -         -   \n",
       "\n",
       "  Elasticエラー詳細  \n",
       "0            -  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.5.補助列を追加\n",
    "inputdata[['number_of_pages',\n",
    "           '重複チェック', 'URL判定', 'DL判定', 'DLエラー詳細', '画像化', '画像化エラー詳細',\n",
    "           'テキスト解析', '解析エラー詳細','OCR解析', 'OCRエラー詳細',\n",
    "           'GCP格納','GCPエラー詳細', '画像格納' , '画像格納エラー詳細',\n",
    "           'Elastic格納' , 'Elasticエラー詳細']] = '-'\n",
    "\n",
    "#1.6. astype()\n",
    "inputdata['fiscal_year_start']=inputdata['fiscal_year_start'].astype(int)\n",
    "inputdata['fiscal_year_end']=inputdata['fiscal_year_end'].astype(int)\n",
    "inputdata['submit_id']=inputdata['submit_id'].astype(int)\n",
    "inputdata.collected_at= pd.to_datetime(inputdata.collected_at)\n",
    "\n",
    "#1.7 codeフォーマット変換\n",
    "def format_code(row):\n",
    "    if any(row['affiliation'].endswith(suffix) for suffix in ['都', '道', '府', '県']):\n",
    "        # 都道府県は6桁\n",
    "        return str(row['code']).zfill(6)\n",
    "    else:\n",
    "        # その他（省庁）は5桁\n",
    "        return str(row['code']).zfill(5)\n",
    "    \n",
    "inputdata['code'] = inputdata['code'].astype(int)\n",
    "inputdata['code'] = inputdata.apply(format_code, axis=1)\n",
    "\n",
    "#1.8 \n",
    "#数字、スペース、アルファベットは半角に統一。\n",
    "#【】（）「」・＜＞は、全角に統一。\n",
    "import pandas as pd\n",
    "\n",
    "# 示例DataFrame\n",
    "def half_to_full(text):\n",
    "    result = \"\"\n",
    "    for char in text:\n",
    "        code = ord(char)\n",
    "        # 数字、英文字母、空格的半角转全角\n",
    "        if 0x21 <= code <= 0x7E:\n",
    "            result += chr(code + 0xFEE0)\n",
    "        elif code == 0x20:  # 半角空格\n",
    "            result += chr(0x3000)\n",
    "        else:\n",
    "            result += char\n",
    "    return result\n",
    "\n",
    "def specific_symbols_to_full(text):\n",
    "    half_to_full_map = {\n",
    "        '(': '（', ')': '）',\n",
    "        '[': '【', ']': '】',\n",
    "        '<': '＜', '>': '＞',\n",
    "    }\n",
    "    for half, full in half_to_full_map.items():\n",
    "        text = text.replace(half, full)\n",
    "    return text\n",
    "\n",
    "inputdata.title = inputdata.title.apply(half_to_full)\n",
    "inputdata.title = inputdata.title.apply(specific_symbols_to_full)\n",
    "\n",
    "#1.9 reset_index()\n",
    "inputdata=inputdata.reset_index(drop=True)\n",
    "\n",
    "#2. 団体コード/カテゴリーID付与\n",
    "#2,1  団体コード付与\n",
    "inputdata.loc[:, \"affiliation_code\"] = inputdata['code'].map(lambda x:str(x)[:2])\n",
    "inputdata.loc[:, \"organization_code\"] = inputdata['code'].map(lambda x:str(x)[2:])\n",
    "\n",
    "#2,2 カテゴリーID付与\n",
    "inputdata_category=pd.merge(inputdata,df_config_category,\n",
    "         left_on=['category_name'],\n",
    "         right_on=['category（論理名称）'], how='left')\n",
    "time.sleep(3)\n",
    "inputdata.loc[:, \"category\"] = inputdata_category[\"categoryにセットする値（※データ型はint）\"]\n",
    "del inputdata_category\n",
    "\n",
    "#2,3 サブカテゴリーID付与\n",
    "inputdata_subcategory=pd.merge(inputdata,df_config_subcategory,\n",
    "         left_on=['sub_category_name'],\n",
    "         right_on=['sub_categoryにセットできる値（論理名称）'], how='left')\n",
    "time.sleep(3)\n",
    "inputdata.loc[:, \"sub_category\"] = inputdata_subcategory[\"sub_categoryにセットできる値（※データ型はint）\"].fillna('-')\n",
    "del inputdata_subcategory\n",
    "\n",
    "#3.URL重複チェック (0＝重複なし、1＝自重複、２＝過去と重複)\n",
    "#3.1.今回提出分での比較\n",
    "inputdata['重複チェック'] = 0\n",
    "inputdata['重複チェック'].where(~inputdata.duplicated(subset=['source_url', 'category', 'sub_category'], keep='first'), 1, inplace=True)\n",
    "\n",
    "#3.2.過去解析分との比較\n",
    "# (source_url, category, sub_category)の組み合わせをtupleとしてsetに保存\n",
    "# url_set = set(tuple(x) for x in last_submit_id_tables[['source_url', 'category', 'sub_category']].to_numpy())\n",
    "\n",
    "# inputdata内の各行をイテレートし、重複チェックが0の行だけを確認\n",
    "# for index, row in inputdata.loc[inputdata['重複チェック'] == 0].iterrows():\n",
    "#     # 行から(source_url, category, sub_category)の組み合わせをtupleとして抽出\n",
    "#     row_tuple = tuple(row[['source_url', 'category', 'sub_category']])\n",
    "    \n",
    "#     # この組み合わせがurl_set内に存在するかチェック\n",
    "#     if row_tuple in url_set:\n",
    "#         inputdata.at[index, '重複チェック'] = 2\n",
    "# del url_set\n",
    "\n",
    "#reindex\n",
    "inputdata=inputdata.reindex(columns=['title','category','category_name', 'sub_category', 'sub_category_name',\n",
    "        'file_id','number_of_pages','code', 'affiliation_code','affiliation','organization_code','organization',\n",
    "        'fiscal_year_start', 'fiscal_year_end', 'source_url',\n",
    "        'collected_at', 'modified_at', 'submit_id', 'server_name',\n",
    "        '重複チェック', 'URL判定', 'DL判定', 'DLエラー詳細', '画像化', '画像化エラー詳細',\n",
    "        'テキスト解析', '解析エラー詳細','OCR解析', 'OCRエラー詳細',\n",
    "        'GCP格納','GCPエラー詳細', '画像格納' , '画像格納エラー詳細', \n",
    "        'Elastic格納' , 'Elasticエラー詳細'])\n",
    "\n",
    "#カテゴリーID付与失敗有無のチェック\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'),' INPUTDATA構成完了')\n",
    "print('カテゴリID付与失敗数：',len(inputdata[inputdata['category'].isna()].groupby(['category']).count()))\n",
    "print('サブカテゴリーID付与失敗数：',len(inputdata[inputdata['sub_category'].isna()].groupby(['sub_category']).count()))\n",
    "\n",
    "inputdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d6977b",
   "metadata": {},
   "source": [
    "## 4.ダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d9e7f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-24 15:29:36 ファイルDL開始\n",
      "2025-04-24 15:29:37 進捗: 100.00%\n",
      "2025-04-24 15:29:37 ファイルDL完了\n"
     ]
    }
   ],
   "source": [
    "#4,1 URL判定\n",
    "for index, row in inputdata[inputdata['重複チェック'] == 0].iterrows():\n",
    "    if row['source_url'].startswith((\"http://\", \"https://\")):\n",
    "        inputdata.at[index, 'URL判定'] = 0\n",
    "    else:\n",
    "        #error1.URLではありません\n",
    "        inputdata.at[index, 'URL判定'] = 1\n",
    "                \n",
    "#4.2 ダウンロード\n",
    "#4.2.1.ドメインを軸にシャフルする\n",
    "from urllib.parse import urlparse\n",
    "from collections import defaultdict\n",
    "\n",
    "shuffled_data=inputdata.copy()\n",
    "shuffled_data['domain'] = shuffled_data['source_url'].apply(lambda x: urlparse(x).netloc)\n",
    "\n",
    "# 各ドメインの行を辞書に収集する\n",
    "domain_rows = defaultdict(list)\n",
    "for index, row in shuffled_data.iterrows():\n",
    "    domain_rows[row['domain']].append(row)\n",
    "\n",
    "# 各ドメインのリストから交互に行を取り出し、順序をシャッフルする\n",
    "shuffled_data_list = []\n",
    "while domain_rows:  # 辞書が空でない間処理を続ける\n",
    "    for domain in list(domain_rows):  # イテレート中に辞書を変更しないように list() を使用\n",
    "        shuffled_data_list.append(domain_rows[domain].pop(0))  # 各リストから1つ要素を取り出す\n",
    "        if not domain_rows[domain]:  # 現在のドメインのリストが空になった場合は辞書から削除\n",
    "            del domain_rows[domain]\n",
    "\n",
    "# リストを DataFrame に変換\n",
    "shuffled_data = pd.DataFrame(shuffled_data_list)\n",
    "\n",
    "#4.2.2.シャフルのままDLする\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36'}\n",
    "\n",
    "#進捗表示関連\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S')+' ファイルDL開始')\n",
    "total_rows = len(shuffled_data)\n",
    "readed_files = 0\n",
    "\n",
    "#スパム対策関連\n",
    "recent_downloads = {}\n",
    "\n",
    "for index, row in shuffled_data.iterrows():\n",
    "    #スパム対策：直近DLしたことのあるサイトの場合、5秒以上待つ\n",
    "    domain = row['domain']\n",
    "    now = datetime.now()\n",
    "    \n",
    "    if domain in recent_downloads:\n",
    "        last_download_time = recent_downloads[domain]\n",
    "        time_diff = now - last_download_time\n",
    "        \n",
    "        if time_diff < timedelta(seconds=5):\n",
    "            time.sleep(random.randint(5, 7)) \n",
    "            \n",
    "    try:\n",
    "        response = requests.get(row['source_url'],headers=headers,verify=False)\n",
    "        response.raise_for_status() #リクエスト結果を確認（ダウンロード不可の時は即終了）\n",
    "        save_as=temp_folder+'pdf/'+row.file_id+'.pdf'\n",
    "\n",
    "        with open(save_as, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    file.write(chunk)\n",
    "                    file.flush()\n",
    "        inputdata.at[index, 'DL判定'] = 0\n",
    "        \n",
    "        #ハッシュ値取得\n",
    "        inputdata.at[index, 'hash'] = calculate_sha256(save_as)\n",
    "            \n",
    "    except Exception as e:\n",
    "        #error1.ダウンロードに失敗しました\n",
    "        inputdata.at[index, 'DL判定'] = 1\n",
    "        inputdata.at[index, 'DLエラー詳細'] = str(e)\n",
    "    \n",
    "    if len(recent_downloads) >= 10:\n",
    "        oldest_domain = min(recent_downloads, key=recent_downloads.get)\n",
    "        del recent_downloads[oldest_domain]\n",
    "    \n",
    "    recent_downloads[domain] = datetime.now()\n",
    "    \n",
    "    #進捗表示\n",
    "    readed_files += 1\n",
    "    percentage = (readed_files / total_rows) * 100\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f'\\r{current_time} 進捗: {percentage:.2f}%', end='')\n",
    "\n",
    "step_message=datetime.now().strftime('%Y-%m-%d %H:%M:%S')+' ファイルDL完了'\n",
    "print('\\n'+step_message)\n",
    "# twillo_message=server_message+\"より\\n\"+step_message\n",
    "#send_twilio_message(twilio_variables,twillo_message)\n",
    "\n",
    "#以下追加処理(仮：画像化)\n",
    "#使うのはtemp_folderのPDFファイル\n",
    "\n",
    "#進捗表示関連\n",
    "# print(datetime.now().strftime('%Y-%m-%d %H:%M:%S')+' 画像化開始')\n",
    "# total_rows = len(inputdata[inputdata['DL判定'] == 0])\n",
    "# readed_files = 0\n",
    "\n",
    "# for index, row in inputdata[inputdata['DL判定'] == 0].iterrows():   \n",
    "#     file_id=row.file_id\n",
    "#     pdf_path=temp_folder+'pdf/'+file_id+'.pdf'\n",
    "        \n",
    "#     #画像化(pdf2image)\n",
    "#     preview_dirpath=temp_folder+'preview/'+file_id+'/'\n",
    "#     try:\n",
    "#         convert_to_pic_500(pdf_path, preview_dirpath)\n",
    "#         inputdata.at[index, '画像化'] = 0\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         inputdata.at[index, '画像化'] = 1\n",
    "#         inputdata.at[index, '画像化エラー詳細'] = str(e)\n",
    "    \n",
    "#     #進捗表示\n",
    "#     readed_files += 1\n",
    "#     percentage = (readed_files / total_rows) * 100\n",
    "#     current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "#     print(f'\\r{current_time} 進捗: {percentage:.2f}%', end='')\n",
    "\n",
    "# step_message=datetime.now().strftime('%Y-%m-%d %H:%M:%S')+' 画像化完了'\n",
    "# print('\\n'+step_message)\n",
    "# # twillo_message=server_message+\"より\\n\"+step_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c54fa",
   "metadata": {},
   "source": [
    "## 5.PDFからテキストを抽出し、CSVとして保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a77bbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-24 15:29:41 テキスト解析開始\n",
      "2025-04-24 15:29:41 進捗: 100.00%\n",
      "→ 画像あり: file_id=AA0163873, page=1\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=2\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=3\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=4\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=5\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=6\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=7\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=8\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=12\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=14\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=15\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=16\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=17\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=18\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=19\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=20\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=21\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=22\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=23\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=24\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=25\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=26\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=27\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=28\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=29\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=30\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=31\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=32\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=33\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=34\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=35\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=36\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=38\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=39\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=40\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=41\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=42\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=44\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=45\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=46\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=47\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=48\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=49\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=50\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=51\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=52\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=53\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=54\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=55\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=56\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=57\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=58\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=59\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=60\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=61\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=62\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=63\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=64\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=65\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=66\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=67\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=68\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=69\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=70\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=71\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=72\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=73\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=74\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=75\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=76\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=78\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=79\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=80\n",
      "\n",
      "→ 画像あり: file_id=AA0163873, page=82\n",
      "\n",
      "OCR対象: file_id=AA0163873, pages=[1, 2, 3, 4, 5, 6, 7, 8, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82]\n",
      "\n",
      "2025-04-24 15:38:36 テキスト解析完了\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'テキスト解析開始')\n",
    "\n",
    "# DL判定=0 の行だけ対象\n",
    "target_df = inputdata[inputdata['DL判定'] == 0].copy()\n",
    "total_rows = len(target_df)\n",
    "readed_files = 0\n",
    "\n",
    "for index, row in target_df.iterrows():\n",
    "    readed_files += 1\n",
    "    percentage = (readed_files / total_rows) * 100\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f'\\r{current_time} 進捗: {percentage:.2f}%', end='')\n",
    "\n",
    "    file_id = row.file_id\n",
    "    pdf_path = os.path.join(temp_folder, 'pdf', f\"{file_id}.pdf\")\n",
    "\n",
    "    # ---------- 1) PDFを開いてページ数を取得 ----------\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            number_of_pages = len(pdf.pages)\n",
    "            inputdata.at[index, 'number_of_pages'] = number_of_pages\n",
    "    except Exception as e:\n",
    "        inputdata.at[index, 'テキスト解析'] = 1\n",
    "        inputdata.at[index, '解析エラー詳細'] = \"[PDF開けません] \" + str(e)\n",
    "        continue\n",
    "\n",
    "    # ページ単位のテキスト結果をためるDataFrame\n",
    "    df_content = pd.DataFrame(columns=['_id','file_id','file_page','content_text','TF'])\n",
    "    # OCRを必要とするページをリストで管理\n",
    "    pages_for_ocr = []\n",
    "    # エラーフラグ（文字化け・空白・文字数不足）\n",
    "    error_check_3 = error_check_4 = error_check_5 = 0\n",
    "\n",
    "    # ---------- 2) pdfplumberでテキスト抽出 ----------\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                page_num = page.page_number\n",
    "                _id = f\"{file_id}E{str(page_num).zfill(8)}E\"\n",
    "\n",
    "                # 画像があるかどうかチェック\n",
    "                images_info = page.images\n",
    "                has_image = (len(images_info) > 0)\n",
    "                if has_image:\n",
    "                    print(f\"\\n→ 画像あり: file_id={file_id}, page={page_num}\")\n",
    "\n",
    "                # pdfplumberテキスト抽出\n",
    "                content_text = page.dedupe_chars(tolerance=1).extract_text() or \"\"\n",
    "                s_text = content_text.strip()\n",
    "\n",
    "                # OCR対象かどうか判定（画像があれば即OCR）\n",
    "                if has_image:\n",
    "                    pages_for_ocr.append(page_num)\n",
    "\n",
    "                #文字化けの場合\n",
    "                elif \"cid:\" in content_text:\n",
    "                    error_check_3 = 1\n",
    "                    pages_for_ocr.append(page_num)\n",
    "                \n",
    "                # 空白ページ\n",
    "                elif s_text == \"\":\n",
    "                    error_check_4 = 1\n",
    "                    pages_for_ocr.append(page_num)\n",
    "                \n",
    "                else:\n",
    "                    # pdfplumber で正常にテキスト取得\n",
    "                    tokens = mecab_list(content_text)\n",
    "                    tf_result = dict(collections.Counter(tokens).most_common(50))\n",
    "                    row_data = pd.DataFrame(\n",
    "                        [[_id, file_id, page_num, content_text, tf_result]],\n",
    "                        columns=['_id','file_id','file_page','content_text','TF']\n",
    "                    )\n",
    "                    df_content = pd.concat([df_content, row_data], ignore_index=True)\n",
    "\n",
    "        # ---------- 3) 必要ページだけ OCR -----------\n",
    "        if pages_for_ocr:\n",
    "            print(f\"\\nOCR対象: file_id={file_id}, pages={pages_for_ocr}\")\n",
    "\n",
    "            for pnum in pages_for_ocr:\n",
    "                try:\n",
    "                    # (A) PDFを画像化 (メモリ上)\n",
    "                    image_list = get_page_image_in_memory(pdf_path, pnum, size=1500)\n",
    "                    # (B) 1ページ1イメージ想定だが、念のためループ\n",
    "                    from PIL import ImageEnhance  # PillowのImageEnhanceを利用\n",
    "                    for pil_img in image_list:\n",
    "                        # コントラスト調整（例: 1.5倍）\n",
    "                        enhancer = ImageEnhance.Contrast(pil_img)\n",
    "                        pil_img_adjusted = enhancer.enhance(1.5)  # 必要に応じて調整\n",
    "                        # (B) GeminiでOCR（指数バックオフ付き）\n",
    "                        ocr_text = gemini_ocr_with_backoff(\n",
    "                            pil_img_adjusted, \n",
    "                            prompt=\"画像から必ず全てのテキストを抽出して、抽出したテキストは必ず***と***で挟んでください。\", \n",
    "                            max_retries=5, \n",
    "                            initial_delay=5\n",
    "                        )\n",
    "                        # OCR結果から各ページごとに角括弧内のテキストだけを抽出（複数ある場合は連結）\n",
    "                        ocr_text = extract_inside_asterisks(ocr_text)\n",
    "\n",
    "                        # (D) DataFrameにOCR結果を格納\n",
    "                        _id_ocr = f\"{file_id}E{str(pnum).zfill(8)}E_OCR\"\n",
    "                        tokens = mecab_list(ocr_text)\n",
    "                        tf_result = dict(collections.Counter(tokens).most_common(50))\n",
    "                        row_data = pd.DataFrame(\n",
    "                            [[_id_ocr, file_id, pnum, ocr_text, tf_result]],\n",
    "                            columns=['_id','file_id','file_page','content_text','TF']\n",
    "                        )\n",
    "                        df_content = pd.concat([df_content, row_data], ignore_index=True)\n",
    "\n",
    "                except Exception as e:\n",
    "                    error_details = traceback.format_exc()\n",
    "                    print(f\"[OCRエラー] file_id={file_id}, page={pnum}, エラー詳細:\\n{error_details}\")\n",
    "                    continue\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        inputdata.at[index, 'テキスト解析'] = 6\n",
    "        inputdata.at[index, '解析エラー詳細'] = \"[その他の不明エラー] \" + str(e)\n",
    "        continue\n",
    "\n",
    "    # ---------- 4) 結果をCSVに出力 ----------\n",
    "    if not df_content.empty:\n",
    "        df_content = df_content.sort_values(by='file_page').reset_index(drop=True)\n",
    "        csv_path = os.path.join(local_save_folder, 'csv', f\"{file_id}.csv\")\n",
    "        df_content.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "        inputdata.at[index, 'テキスト解析'] = 0  # 正常完了\n",
    "    else:\n",
    "        # df_contentが空 → ページ抽出エラー等\n",
    "        if error_check_3 == 1:\n",
    "            inputdata.at[index, 'テキスト解析'] = 3\n",
    "            inputdata.at[index, '解析エラー詳細'] = \"[文字化けです]\"\n",
    "        elif error_check_4 == 1:\n",
    "            inputdata.at[index, 'テキスト解析'] = 4\n",
    "            inputdata.at[index, '解析エラー詳細'] = \"[空白ページです]\"\n",
    "        elif error_check_5 == 1:\n",
    "            inputdata.at[index, 'テキスト解析'] = 5\n",
    "            inputdata.at[index, '解析エラー詳細'] = \"[文字数が足りません]\"\n",
    "        else:\n",
    "            inputdata.at[index, 'テキスト解析'] = 2\n",
    "            inputdata.at[index, '解析エラー詳細'] = \"[記入できるデータがありません]\"\n",
    "\n",
    "print('\\n' + datetime.now().strftime('%Y-%m-%d %H:%M:%S') + ' テキスト解析完了')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e0e620",
   "metadata": {},
   "source": [
    "## 6.TF-IDF特徴語タグの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "77d9ebfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-16 11:03:43 TFIDF解析開始（対象ファイル数1*1組）\n",
      "2025-01-16 11:03:43 進捗: 100.00%\n",
      "2025-01-16 11:03:43 タグ解析完了\n"
     ]
    }
   ],
   "source": [
    "filtered_data = inputdata[inputdata['テキスト解析'] == 0]\n",
    "total_rows = len(filtered_data)\n",
    "\n",
    "#6.1.最も合理的な解析回数を算出\n",
    "def calculate_group_distribution(total_files, min_files_per_group=300, max_files_per_group=500):\n",
    "    for group_count in range(4, 0, -1):  # グループ数を4から1まで試す\n",
    "        if total_files / group_count <= max_files_per_group and (total_files / group_count >= min_files_per_group or group_count == 1):\n",
    "            return group_count, math.ceil(total_files / group_count)\n",
    "    return 1, total_files  \n",
    "num_batches, batch_size = calculate_group_distribution(total_rows)\n",
    "\n",
    "#進捗表示関連\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S')+' TFIDF解析開始（対象ファイル数'+str(batch_size)+'*'+str(num_batches)+'組）')\n",
    "readed_files = 0\n",
    "for n in range(num_batches):\n",
    "    start_index = n * batch_size\n",
    "    end_index = min((n + 1) * batch_size, total_rows)  # 合計長さを超えないようにする\n",
    "    batch_data = filtered_data.iloc[start_index:end_index]\n",
    "    \n",
    "    # 6.2..作業用データフレームの形成\n",
    "    df_contents=pd.DataFrame(columns=['_id', 'file_id', 'file_page', 'content_text', 'TF'])\n",
    "    for index, row in batch_data.iterrows():\n",
    "        #...df_contents=df_contents.append(pd.read_csv(local_save_folder+'csv/'+row.file_id+'.csv',encoding=\"utf-8\"))\n",
    "        df_contents = pd.concat([df_contents, pd.read_csv(local_save_folder + 'csv/' + row.file_id + '.csv', encoding=\"utf-8\")])\n",
    "\n",
    "    df_contents.TF=df_contents.TF.map(lambda x:eval(x))\n",
    "\n",
    "    #6.3 IDF\n",
    "    #【Python】TF-IDF を使って自分のブログの特徴を取得してみた\n",
    "    #https://dev.classmethod.jp/articles/python-tfidf-blog/#orgdcd1e4a\n",
    "    #全文書数J\n",
    "    j=len(df_contents)\n",
    "\n",
    "    #単語Wiが登場する文書数\n",
    "    idf_doc={}\n",
    "    for row_tf in df_contents.TF:\n",
    "        for term,frequence in row_tf.items():\n",
    "            if term in idf_doc:\n",
    "                idf_doc[term]=idf_doc[term]+1\n",
    "            else:\n",
    "                idf_doc[term]=1\n",
    "\n",
    "    #idf\n",
    "    idf={}\n",
    "    for k,v in idf_doc.items():\n",
    "        idf[k]=math.log((1+j)/v)\n",
    "\n",
    "    #tfidf score\n",
    "    tfidfs=[]\n",
    "    for row_tf in df_contents.TF:\n",
    "        row_sum=sum(row_tf.values())\n",
    "        tfidflist={}\n",
    "        for term,frequence in row_tf.items():\n",
    "            TermFrequence=frequence/row_sum\n",
    "            tfidf=round(TermFrequence*idf[term],3)\n",
    "            tfidflist[term]=tfidf\n",
    "\n",
    "        #order by tf-idf_value, and pick up top30 as dict\n",
    "        sorted_tfidf=dict(sorted(tfidflist.items(), key=lambda item:item[1],reverse=True)[:30])\n",
    "        tfidfs.append(list(sorted_tfidf.keys()))\n",
    "\n",
    "    df_contents[\"tags\"]=tfidfs\n",
    "\n",
    "    #6.4 タグ結果をCSVに追記\n",
    "    for index, row in batch_data.iterrows():\n",
    "        file_id=row.file_id\n",
    "\n",
    "        #FildIDごとの解析結果をCSVとして出力\n",
    "        csv_path=local_save_folder+'csv/'+file_id+'.csv'\n",
    "\n",
    "        df_content=df_contents[df_contents.file_id==file_id]\n",
    "        df_content.to_csv(csv_path, index=False)\n",
    "        \n",
    "        readed_files += 1\n",
    "        percentage = (readed_files / total_rows) * 100\n",
    "        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f'\\r{current_time} 進捗: {percentage:.2f}%', end='')\n",
    "        \n",
    "step_message=datetime.now().strftime('%Y-%m-%d %H:%M:%S')+' タグ解析完了'\n",
    "print('\\n'+step_message)\n",
    "# twillo_message=server_message+\"より\\n\"+step_message\n",
    "#send_twilio_message(twilio_variables,twillo_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d605ccc",
   "metadata": {},
   "source": [
    "## 7.Elasticアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "07b22ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-02 22:45:18 Elasticアップロード開始\n",
      "2024-11-02 22:56:44 進捗: 100.00%\n",
      "2024-11-02 22:56:44 Elasticアップロード完了\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>sub_category_name</th>\n",
       "      <th>file_id</th>\n",
       "      <th>number_of_pages</th>\n",
       "      <th>code</th>\n",
       "      <th>affiliation_code</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>organization_code</th>\n",
       "      <th>organization</th>\n",
       "      <th>fiscal_year_start</th>\n",
       "      <th>fiscal_year_end</th>\n",
       "      <th>source_url</th>\n",
       "      <th>collected_at</th>\n",
       "      <th>modified_at</th>\n",
       "      <th>submit_id</th>\n",
       "      <th>server_name</th>\n",
       "      <th>重複チェック</th>\n",
       "      <th>URL判定</th>\n",
       "      <th>DL判定</th>\n",
       "      <th>DLエラー詳細</th>\n",
       "      <th>画像化</th>\n",
       "      <th>画像化エラー詳細</th>\n",
       "      <th>テキスト解析</th>\n",
       "      <th>解析エラー詳細</th>\n",
       "      <th>OCR解析</th>\n",
       "      <th>OCRエラー詳細</th>\n",
       "      <th>GCP格納</th>\n",
       "      <th>GCPエラー詳細</th>\n",
       "      <th>画像格納</th>\n",
       "      <th>画像格納エラー詳細</th>\n",
       "      <th>Elastic格納</th>\n",
       "      <th>Elasticエラー詳細</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, category, category_name, sub_category, sub_category_name, file_id, number_of_pages, code, affiliation_code, affiliation, organization_code, organization, fiscal_year_start, fiscal_year_end, source_url, collected_at, modified_at, submit_id, server_name, 重複チェック, URL判定, DL判定, DLエラー詳細, 画像化, 画像化エラー詳細, テキスト解析, 解析エラー詳細, OCR解析, OCRエラー詳細, GCP格納, GCPエラー詳細, 画像格納, 画像格納エラー詳細, Elastic格納, Elasticエラー詳細, hash]\n",
       "Index: []"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.1.認証ファイル取得\n",
    "with open(elastic_password_path, 'r', encoding='utf-8') as f:\n",
    "    auth=f.readlines()\n",
    "    dev_auth=auth[5].split(\",\")\n",
    "    dev_auth[2]=\"https://\"+dev_auth[2].replace(\"\\n\",\".es.asia-northeast1.gcp.cloud.es.io:9243\")\n",
    "    dev_mode=tuple(dev_auth)\n",
    "    prod_auth=auth[9].split(\",\")\n",
    "    prod_auth[2]=\"https://\"+prod_auth[2].replace(\"\\n\",\".es.asia-northeast1.gcp.cloud.es.io:9243\")\n",
    "    prod_mode=tuple(prod_auth)\n",
    "    \n",
    "#7.2.Elasticsearchクライアント作成\n",
    "'''\n",
    "重要\n",
    "mode=dev_mode　テスト環境\n",
    "mode=prod_mode　本番環境\n",
    "'''\n",
    "elastic_username,elastic_password,endpoint=prod_mode\n",
    "es = Elasticsearch(endpoint, basic_auth=(elastic_username, elastic_password))\n",
    "\n",
    "#7.3.アップロード用データの作成\n",
    "#進捗表示関連\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S')+' Elasticアップロード開始')\n",
    "total_rows = len(inputdata[inputdata['テキスト解析'] == 0])\n",
    "readed_files = 0\n",
    "\n",
    "for file_index, file_row in inputdata[inputdata['テキスト解析'] == 0].iterrows():\n",
    "    el_msgs={}\n",
    "    page_data=pd.read_csv(local_save_folder+'csv/'+file_row.file_id+'.csv',encoding=\"utf-8\")\n",
    "    \n",
    "    for page_index, page_row in page_data.iterrows():\n",
    "        #_ID取得\n",
    "        elastic_id=str(page_row._id)\n",
    "        if not elastic_id.endswith('E'):\n",
    "            elastic_id = str(elastic_id[:9] + 'E' + elastic_id[9:] + 'E')\n",
    "\n",
    "        current_datetime = datetime.now()\n",
    "        \n",
    "        #page_rowからパラメータをコピー（整形）\n",
    "        page_row['file_id']=str(page_row.file_id)\n",
    "        page_row['file_page']=int(page_row.file_page)\n",
    "        \n",
    "        page_row['tags']=eval(page_row.tags)\n",
    "        del page_row['_id'],page_row['TF']\n",
    "        \n",
    "        #file_rowからパラメータをコピー\n",
    "        page_row['title']=file_row.title\n",
    "        page_row['category']=int(file_row.category)\n",
    "        if file_row.sub_category!=\"-\":\n",
    "            page_row['sub_category']=int(file_row.sub_category)\n",
    "        page_row['number_of_pages']=int(file_row.number_of_pages)\n",
    "        \n",
    "        page_row['code']=str(file_row.code)\n",
    "        page_row['affiliation_code']=str(file_row.affiliation_code)\n",
    "        page_row['organization_code']=str(file_row.organization_code)\n",
    "        \n",
    "        page_row['fiscal_year_start']=int(file_row.fiscal_year_start)\n",
    "        page_row['fiscal_year_end']=int(file_row.fiscal_year_end)\n",
    "        page_row['source_url']=str(file_row.source_url)\n",
    "        page_row['hash']=str(file_row.hash)\n",
    "        \n",
    "        page_row['collected_at']=file_row.collected_at\n",
    "        \n",
    "        #新規パラメータ\n",
    "        page_row['created_at'],page_row['updated_at']=current_datetime,current_datetime\n",
    "        page_row['source_url_is_alive']=True\n",
    "        page_row['published']=1\n",
    "\n",
    "        #順番調整\n",
    "        all_possible_indices = ['title','category','sub_category','file_id', 'file_page',\n",
    "                        'number_of_pages','content_text','code','affiliation_code','organization_code','file_url',\n",
    "                        'fiscal_year_start', 'fiscal_year_end','source_url','source_url_is_alive',\n",
    "                        'collected_at','tags', 'created_at', 'updated_at', 'published','hash']\n",
    "        \n",
    "        existing_indices = [idx for idx in all_possible_indices if idx in page_row.index]\n",
    "        page_row = page_row.reindex(existing_indices)\n",
    "        \n",
    "        #アップロード先のインディクスを取得\n",
    "        get_indices=df_config_category[df_config_category[\n",
    "            'categoryにセットする値（※データ型はint）']==page_row['category']]['インデックス（物理名称）'].values[0]\n",
    "        \n",
    "        try:\n",
    "            uploader = LGDValidator.LocalGovDocumentUploader(elasticsearch_instance=es,\n",
    "                                                             indices=get_indices,\n",
    "                                                             id=elastic_id,\n",
    "                                                             document_data=page_row.to_dict())\n",
    "            uploader.create_document() # 引数が正しい値・データかを検証し、問題なければ、Elasticsearchにドキュメントデータをアップロードする。問題があれば、エラーとなる。\n",
    "        except Exception as e:\n",
    "            # エラー時の処理を記述する。\n",
    "            el_msgs[\"Page:\"+str(page_row.file_page)]=str(e)\n",
    "        \n",
    "    error_pages=len(el_msgs)\n",
    "    if error_pages==0:\n",
    "        #すべてのページが問題なくアップロードできた場合\n",
    "        inputdata.at[file_index, 'Elastic格納'] = 0\n",
    "        inputdata.at[file_index, 'Elasticエラー詳細'] = \"-\"\n",
    "    elif error_pages / len(page_data) >= 0.9:\n",
    "        #90％以上のページがアップロードできなかった場合\n",
    "        inputdata.at[file_index, 'Elastic格納'] = 1\n",
    "        inputdata.at[file_index, 'Elasticエラー詳細'] = list(el_msgs.values())[0]\n",
    "    else:\n",
    "        #10％未満のページがアップロードできなかった場合\n",
    "        inputdata.at[file_index, 'Elastic格納'] = 2\n",
    "        inputdata.at[file_index, 'Elasticエラー詳細'] = el_msgs\n",
    "        \n",
    "    #進捗表示\n",
    "    readed_files += 1\n",
    "    percentage = (readed_files / total_rows) * 100\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f'\\r{current_time} 進捗: {percentage:.2f}%', end='')\n",
    "    \n",
    "step_message=datetime.now().strftime('%Y-%m-%d %H:%M:%S')+' Elasticアップロード完了'\n",
    "print('\\n'+step_message)\n",
    "twillo_message=server_message+\"より\\n\"+step_message\n",
    "#send_twilio_message(twilio_variables,twillo_message)\n",
    "es.close()\n",
    "\n",
    "#error\n",
    "inputdata[~inputdata['Elastic格納'].isin(['-',0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0211c07",
   "metadata": {},
   "source": [
    "## 8.画像化、画像アップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "c4f19901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-02 22:56:44 画像化開始\n",
      "2024-11-02 23:29:41 進捗: 100.00%\n",
      "2024-11-02 23:29:41 画像化完了\n",
      "2024-11-02 23:29:41 画像格納開始\n",
      "2024-11-03 01:04:32 進捗: 100.00%\n",
      "2024-11-03 01:04:32 画像格納完了\n"
     ]
    }
   ],
   "source": [
    "#進捗表示関連\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S')+' 画像化開始')\n",
    "total_rows = len(inputdata[inputdata['Elastic格納'] == 0])\n",
    "readed_files = 0\n",
    "\n",
    "for index, row in inputdata[inputdata['Elastic格納'] == 0].iterrows():   \n",
    "    file_id=row.file_id\n",
    "    pdf_path=temp_folder+'pdf/'+file_id+'.pdf'\n",
    "        \n",
    "    #画像化(pdf2image)\n",
    "    preview_dirpath=temp_folder+'preview/'+file_id+'/'\n",
    "    try:\n",
    "        convert_to_pic_500(pdf_path, preview_dirpath)\n",
    "        inputdata.at[index, '画像化'] = 0\n",
    "        \n",
    "    except Exception as e:\n",
    "        inputdata.at[index, '画像化'] = 1\n",
    "        inputdata.at[index, '画像化エラー詳細'] = str(e)\n",
    "    \n",
    "    #進捗表示\n",
    "    readed_files += 1\n",
    "    percentage = (readed_files / total_rows) * 100\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f'\\r{current_time} 進捗: {percentage:.2f}%', end='')\n",
    "\n",
    "step_message=datetime.now().strftime('%Y-%m-%d %H:%M:%S')+' 画像化完了'\n",
    "print('\\n'+step_message)\n",
    "twillo_message=server_message+\"より\\n\"+step_message\n",
    "#send_twilio_message(twilio_variables,twillo_message)\n",
    "\n",
    "#5.3.gcp_upload\n",
    "#5.3.1.google cloud storageのクライアントインスタンスを作成\n",
    "#Python3からCloud Storageを利用 https://qiita.com/NOGU626/items/88ce6d79b5a22008b004\n",
    "client_prod = storage.Client.from_service_account_json(service_account_path_prod)\n",
    "bucket_prod = client_prod.bucket(bucket_name_prod) #バケットのインスタンスを取得\n",
    "\n",
    "client_backup = storage.Client.from_service_account_json(service_account_path_backup)\n",
    "bucket_backup = client_backup.bucket(bucket_name_backup) #バケットのインスタンスを取得\n",
    "\n",
    "#進捗表示関連\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S')+' 画像格納開始')\n",
    "total_rows = len(inputdata[inputdata['画像化'] == 0])\n",
    "readed_files = 0\n",
    "\n",
    "for index, row in inputdata[inputdata['画像化'] == 0].iterrows():   \n",
    "    file_id=row.file_id\n",
    "    preview_dirpath=temp_folder+'preview/'+file_id+'/'\n",
    "    \n",
    "    #画像アップロード\n",
    "    try:            \n",
    "        for pic_name in os.listdir(preview_dirpath):\n",
    "            #アップロードあとのファイル名を指定(prod)\n",
    "            upload_as_prod='bunsyo/'+file_id+'/'+pic_name\n",
    "            blob_prod = bucket_prod.blob(upload_as_prod)\n",
    "\n",
    "            #アップロードするファイルを指定(prod)\n",
    "            blob_prod.upload_from_filename(preview_dirpath+pic_name)    \n",
    "            \n",
    "        inputdata.at[index, '画像格納'] = 0\n",
    "            \n",
    "    except Exception as e:\n",
    "        #error1.Prodへのアップロードに失敗しました\n",
    "        inputdata.at[index, '画像格納'] = 1\n",
    "        inputdata.at[index, '画像格納エラー詳細'] = str(e)\n",
    "    \n",
    "    finally:\n",
    "        # 删除preview_dirpath内的所有文件\n",
    "        for filename in os.listdir(preview_dirpath):\n",
    "            file_path = os.path.join(preview_dirpath, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.remove(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    # 如果有子文件夹，这里只能删除空的子文件夹\n",
    "                    os.rmdir(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "        \n",
    "        # 尝试删除现在应该为空的preview_dirpath文件夹\n",
    "        try:\n",
    "            os.rmdir(preview_dirpath)\n",
    "        except OSError as e:\n",
    "            print(f\"Error: {preview_dirpath} : {e.strerror}\")\n",
    "        \n",
    "    #進捗表示\n",
    "    readed_files += 1\n",
    "    percentage = (readed_files / total_rows) * 100\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f'\\r{current_time} 進捗: {percentage:.2f}%', end='')\n",
    "    \n",
    "step_message=datetime.now().strftime('%Y-%m-%d %H:%M:%S')+' 画像格納完了'\n",
    "print('\\n'+step_message)\n",
    "twillo_message=server_message+\"より\\n\"+step_message\n",
    "#send_twilio_message(twilio_variables,twillo_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b96631d",
   "metadata": {},
   "source": [
    "## 9. PDF/CSVアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "93d5e999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-03 01:04:32 PDFアップロード開始\n",
      "2024-11-03 01:17:18 進捗: 100.00%\n",
      "データフレーム格納先：../bunsyo/pickle/202411011_Earth_DataFrame.pkl\n",
      "2024-11-03 01:17:20 PDFアップロード完了\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>sub_category_name</th>\n",
       "      <th>file_id</th>\n",
       "      <th>number_of_pages</th>\n",
       "      <th>code</th>\n",
       "      <th>affiliation_code</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>organization_code</th>\n",
       "      <th>organization</th>\n",
       "      <th>fiscal_year_start</th>\n",
       "      <th>fiscal_year_end</th>\n",
       "      <th>source_url</th>\n",
       "      <th>collected_at</th>\n",
       "      <th>modified_at</th>\n",
       "      <th>submit_id</th>\n",
       "      <th>server_name</th>\n",
       "      <th>重複チェック</th>\n",
       "      <th>URL判定</th>\n",
       "      <th>DL判定</th>\n",
       "      <th>DLエラー詳細</th>\n",
       "      <th>画像化</th>\n",
       "      <th>画像化エラー詳細</th>\n",
       "      <th>テキスト解析</th>\n",
       "      <th>解析エラー詳細</th>\n",
       "      <th>OCR解析</th>\n",
       "      <th>OCRエラー詳細</th>\n",
       "      <th>GCP格納</th>\n",
       "      <th>GCPエラー詳細</th>\n",
       "      <th>画像格納</th>\n",
       "      <th>画像格納エラー詳細</th>\n",
       "      <th>Elastic格納</th>\n",
       "      <th>Elasticエラー詳細</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, category, category_name, sub_category, sub_category_name, file_id, number_of_pages, code, affiliation_code, affiliation, organization_code, organization, fiscal_year_start, fiscal_year_end, source_url, collected_at, modified_at, submit_id, server_name, 重複チェック, URL判定, DL判定, DLエラー詳細, 画像化, 画像化エラー詳細, テキスト解析, 解析エラー詳細, OCR解析, OCRエラー詳細, GCP格納, GCPエラー詳細, 画像格納, 画像格納エラー詳細, Elastic格納, Elasticエラー詳細, hash]\n",
       "Index: []"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rows = len(inputdata[inputdata['DL判定'] == 0])\n",
    "readed_files = 0\n",
    "\n",
    "#Python3からCloud Storageを利用 https://qiita.com/NOGU626/items/88ce6d79b5a22008b004\n",
    "client_prod = storage.Client.from_service_account_json(service_account_path_prod)\n",
    "bucket_prod = client_prod.bucket(bucket_name_prod) #バケットのインスタンスを取得\n",
    "\n",
    "client_backup = storage.Client.from_service_account_json(service_account_path_backup)\n",
    "bucket_backup = client_backup.bucket(bucket_name_backup) #バケットのインスタンスを取得\n",
    "\n",
    "#進捗表示関連\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S')+' PDFアップロード開始')\n",
    "for index, row in inputdata[inputdata['DL判定'] == 0].iterrows():\n",
    "    file_id=row.file_id\n",
    "    pdf_path=temp_folder+'pdf/'+file_id+'.pdf'\n",
    "    csv_path=local_save_folder+'csv/'+file_id+'.csv'\n",
    "\n",
    "    inputdata.at[index, 'GCP格納'] = {}\n",
    "    inputdata.at[index, 'GCPエラー詳細'] = {}\n",
    "\n",
    "    #PDFアップロード（Prod）\n",
    "    try:            \n",
    "        #アップロードあとのファイル名を指定（Prod）\n",
    "        upload_as_prod='bunsyo/'+file_id+'.pdf'\n",
    "        blob_prod = bucket_prod.blob(upload_as_prod)\n",
    "\n",
    "        #アップロードするファイルを指定（Prod）\n",
    "        blob_prod.upload_from_filename(pdf_path)\n",
    "\n",
    "        inputdata.at[index, 'GCP格納']['Prod'] = 0\n",
    "        inputdata.at[index, 'GCPエラー詳細']['Prod'] = 0\n",
    "\n",
    "    except Exception as e:\n",
    "        #アップロードに失敗しました\n",
    "        inputdata.at[index, 'GCP格納']['Prod'] = 1\n",
    "        inputdata.at[index, 'GCPエラー詳細']['Prod'] = str(e)\n",
    "\n",
    "    #進捗表示（Prod）\n",
    "    readed_files += 0.5\n",
    "    percentage = (readed_files / total_rows) * 100\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f'\\r{current_time} 進捗: {percentage:.2f}%', end='')\n",
    "\n",
    "    #PDFアップロード（Backup）\n",
    "    try:            \n",
    "        #アップロードあとのファイル名を指定（Backup）\n",
    "        upload_as_backup='bunsyo/pdf/'+file_id+'.pdf'\n",
    "        blob_backup = bucket_backup.blob(upload_as_backup)\n",
    "\n",
    "        #アップロードするファイルを指定（Backup）\n",
    "        blob_backup.upload_from_filename(pdf_path)\n",
    "\n",
    "        inputdata.at[index, 'GCP格納']['Backup'] = 0\n",
    "        inputdata.at[index, 'GCPエラー詳細']['Backup'] = 0\n",
    "\n",
    "    except Exception as e:\n",
    "        #アップロードに失敗しました\n",
    "        inputdata.at[index, 'GCP格納']['Backup'] = 1\n",
    "        inputdata.at[index, 'GCPエラー詳細']['Backup'] = str(e)\n",
    "\n",
    "\n",
    "    #CSVアップロード（Backup）\n",
    "    if os.path.exists(csv_path):\n",
    "        try:            \n",
    "            #アップロードあとのファイル名を指定（Backup）\n",
    "            upload_as_backup='bunsyo/csv/'+file_id+'.csv'\n",
    "            blob_backup = bucket_backup.blob(upload_as_backup)\n",
    "\n",
    "            #アップロードするファイルを指定（Backup）\n",
    "            blob_backup.upload_from_filename(csv_path)\n",
    "\n",
    "            inputdata.at[index, 'GCP格納']['CSV'] = 0\n",
    "            inputdata.at[index, 'GCPエラー詳細']['CSV'] = 0\n",
    "\n",
    "        except Exception as e:\n",
    "            #アップロードに失敗しました\n",
    "            inputdata.at[index, 'GCP格納']['CSV'] = 1\n",
    "            inputdata.at[index, 'GCPエラー詳細']['CSV'] = str(e)\n",
    "\n",
    "    if all(value == 0 for value in inputdata.at[index, 'GCP格納'].values()):\n",
    "        inputdata.at[index, 'GCP格納'] = 0\n",
    "        inputdata.at[index, 'GCPエラー詳細'] = \"-\"\n",
    "\n",
    "    #進捗表示（Prod）\n",
    "    readed_files += 0.5\n",
    "    percentage = (readed_files / total_rows) * 100\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f'\\r{current_time} 進捗: {percentage:.2f}%', end='')\n",
    "\n",
    "\n",
    "#9.1.今回解析結果を出力\n",
    "report_name=str(inputdata.submit_id.min())+\"解析結果レポート.xlsx\"\n",
    "inputdata.set_index(\"file_id\").to_excel(path_teams+path_teams_report_folder+report_name)\n",
    "\n",
    "#9.3.データフレームの保存先\n",
    "pickle_path=r\"../bunsyo/pickle/\"+str(inputdata.submit_id.min())+\"_\"+inputdata['server_name'].iloc[0]+\"_DataFrame.pkl\"\n",
    "inputdata.to_pickle(pickle_path)\n",
    "\n",
    "#end\n",
    "error_count='（失敗：'+str(len(inputdata[~(inputdata['GCP格納'].isin([0,'-']))]))+'件）'\n",
    "step_message=datetime.now().strftime('%Y-%m-%d %H:%M:%S')+' PDFアップロード完了'\n",
    "print('\\n'+'データフレーム格納先：'+pickle_path)\n",
    "print(step_message)\n",
    "\n",
    "twillo_message=server_message+\"より\\n\"+step_message\n",
    "#send_twilio_message(twilio_variables,twillo_message)\n",
    "\n",
    "inputdata[~(inputdata['GCP格納'].isin([0,'-']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42dfe50",
   "metadata": {},
   "source": [
    "## 10.解析結果レポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "6fe6e4e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データフレーム格納先：../bunsyo/pickle/202411011_Earth_DataFrame.pkl\n",
      "2024-11-03 01:17:24 202411011 Earth: All done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>sub_category_name</th>\n",
       "      <th>file_id</th>\n",
       "      <th>number_of_pages</th>\n",
       "      <th>code</th>\n",
       "      <th>affiliation_code</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>organization_code</th>\n",
       "      <th>organization</th>\n",
       "      <th>fiscal_year_start</th>\n",
       "      <th>fiscal_year_end</th>\n",
       "      <th>source_url</th>\n",
       "      <th>collected_at</th>\n",
       "      <th>modified_at</th>\n",
       "      <th>submit_id</th>\n",
       "      <th>server_name</th>\n",
       "      <th>重複チェック</th>\n",
       "      <th>URL判定</th>\n",
       "      <th>DL判定</th>\n",
       "      <th>DLエラー詳細</th>\n",
       "      <th>画像化</th>\n",
       "      <th>画像化エラー詳細</th>\n",
       "      <th>テキスト解析</th>\n",
       "      <th>解析エラー詳細</th>\n",
       "      <th>OCR解析</th>\n",
       "      <th>OCRエラー詳細</th>\n",
       "      <th>GCP格納</th>\n",
       "      <th>GCPエラー詳細</th>\n",
       "      <th>画像格納</th>\n",
       "      <th>画像格納エラー詳細</th>\n",
       "      <th>Elastic格納</th>\n",
       "      <th>Elasticエラー詳細</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>令和６年度一般会計補正予算（第１号）</td>\n",
       "      <td>4</td>\n",
       "      <td>（自治体）予算</td>\n",
       "      <td>6</td>\n",
       "      <td>（自治体）補正予算</td>\n",
       "      <td>AA0178569</td>\n",
       "      <td>17</td>\n",
       "      <td>462187</td>\n",
       "      <td>46</td>\n",
       "      <td>鹿児島県</td>\n",
       "      <td>2187</td>\n",
       "      <td>霧島市</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.city-kirishima.jp/zaisei/documents...</td>\n",
       "      <td>2024-03-30 15:55:00</td>\n",
       "      <td></td>\n",
       "      <td>202411011</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0de6d82659dfe18a05c6d8e3f9103630c9312580028ea8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>令和６年度一般会計補正予算説明資料（第１号）</td>\n",
       "      <td>4</td>\n",
       "      <td>（自治体）予算</td>\n",
       "      <td>6</td>\n",
       "      <td>（自治体）補正予算</td>\n",
       "      <td>AA0178570</td>\n",
       "      <td>2</td>\n",
       "      <td>462187</td>\n",
       "      <td>46</td>\n",
       "      <td>鹿児島県</td>\n",
       "      <td>2187</td>\n",
       "      <td>霧島市</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.city-kirishima.jp/zaisei/documents...</td>\n",
       "      <td>2024-03-30 15:55:00</td>\n",
       "      <td></td>\n",
       "      <td>202411011</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>3508cafe855bb9dbb39bf10fb255539433f86e073be545...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>令和６年度４月補正予算（専決）</td>\n",
       "      <td>4</td>\n",
       "      <td>（自治体）予算</td>\n",
       "      <td>6</td>\n",
       "      <td>（自治体）補正予算</td>\n",
       "      <td>AA0178571</td>\n",
       "      <td>7</td>\n",
       "      <td>462195</td>\n",
       "      <td>46</td>\n",
       "      <td>鹿児島県</td>\n",
       "      <td>2195</td>\n",
       "      <td>いちき串木野市</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.city.ichikikushikino.lg.jp/zaisei1...</td>\n",
       "      <td>2024-03-30 15:55:00</td>\n",
       "      <td></td>\n",
       "      <td>202411011</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>20e887d641164b796ac2d85b324b88bee1362e7f2521a8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>令６年度　一般会計（第１号）補正予算</td>\n",
       "      <td>4</td>\n",
       "      <td>（自治体）予算</td>\n",
       "      <td>6</td>\n",
       "      <td>（自治体）補正予算</td>\n",
       "      <td>AA0178572</td>\n",
       "      <td>8</td>\n",
       "      <td>462233</td>\n",
       "      <td>46</td>\n",
       "      <td>鹿児島県</td>\n",
       "      <td>2233</td>\n",
       "      <td>南九州市</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.city.minamikyushu.lg.jp/material/f...</td>\n",
       "      <td>2024-03-30 15:55:00</td>\n",
       "      <td></td>\n",
       "      <td>202411011</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>98853e537d38c8ff79710cdcd13c48da04b3ca12f6a6ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>令和６年度予算　４月１１日臨時議会　予算説明資料</td>\n",
       "      <td>4</td>\n",
       "      <td>（自治体）予算</td>\n",
       "      <td>6</td>\n",
       "      <td>（自治体）補正予算</td>\n",
       "      <td>AA0178573</td>\n",
       "      <td>2</td>\n",
       "      <td>462233</td>\n",
       "      <td>46</td>\n",
       "      <td>鹿児島県</td>\n",
       "      <td>2233</td>\n",
       "      <td>南九州市</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.city.minamikyushu.lg.jp/material/f...</td>\n",
       "      <td>2024-03-30 15:55:00</td>\n",
       "      <td></td>\n",
       "      <td>202411011</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>fad28051dd3cfca76faa2e4fb16019c34c3a0daf7b62a5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>令和２年度補正予算（議案第８２号～第８３号）－令和２年９月定例月議会</td>\n",
       "      <td>4</td>\n",
       "      <td>（自治体）予算</td>\n",
       "      <td>6</td>\n",
       "      <td>（自治体）補正予算</td>\n",
       "      <td>AA0180496</td>\n",
       "      <td>44</td>\n",
       "      <td>232297</td>\n",
       "      <td>23</td>\n",
       "      <td>愛知県</td>\n",
       "      <td>2297</td>\n",
       "      <td>豊明市</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://www.city.toyoake.lg.jp/secure/18340/R2...</td>\n",
       "      <td>2024-10-09 11:29:00</td>\n",
       "      <td></td>\n",
       "      <td>202411011</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>a16637e927a41fcacaa02b3ccd6c363c879bf01cb273bc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>令和２年度補正予算（議案第５５号・第７４号～第７５号）－令和２年６月定例月議会</td>\n",
       "      <td>4</td>\n",
       "      <td>（自治体）予算</td>\n",
       "      <td>6</td>\n",
       "      <td>（自治体）補正予算</td>\n",
       "      <td>AA0180497</td>\n",
       "      <td>136</td>\n",
       "      <td>232297</td>\n",
       "      <td>23</td>\n",
       "      <td>愛知県</td>\n",
       "      <td>2297</td>\n",
       "      <td>豊明市</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://www.city.toyoake.lg.jp/secure/18097/R2...</td>\n",
       "      <td>2024-10-09 11:31:00</td>\n",
       "      <td></td>\n",
       "      <td>202411011</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0698ddce9919ce25a79eb2e43816561650d0a28a9b61ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>令和２年度補正予算（議案第３８号～第３９号）－令和２年定例会開会議会</td>\n",
       "      <td>4</td>\n",
       "      <td>（自治体）予算</td>\n",
       "      <td>6</td>\n",
       "      <td>（自治体）補正予算</td>\n",
       "      <td>AA0180498</td>\n",
       "      <td>30</td>\n",
       "      <td>232297</td>\n",
       "      <td>23</td>\n",
       "      <td>愛知県</td>\n",
       "      <td>2297</td>\n",
       "      <td>豊明市</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://www.city.toyoake.lg.jp/secure/17736/R2...</td>\n",
       "      <td>2024-10-09 11:33:00</td>\n",
       "      <td></td>\n",
       "      <td>202411011</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>4ad9448d853f70e87c93e556f304356671ad54546dc772...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>令和元年度補正予算（議案第２１号～第２９号）－令和２年３月定例月議会</td>\n",
       "      <td>4</td>\n",
       "      <td>（自治体）予算</td>\n",
       "      <td>6</td>\n",
       "      <td>（自治体）補正予算</td>\n",
       "      <td>AA0180499</td>\n",
       "      <td>193</td>\n",
       "      <td>232297</td>\n",
       "      <td>23</td>\n",
       "      <td>愛知県</td>\n",
       "      <td>2297</td>\n",
       "      <td>豊明市</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://www.city.toyoake.lg.jp/secure/16326/R2...</td>\n",
       "      <td>2024-10-09 11:34:00</td>\n",
       "      <td></td>\n",
       "      <td>202411011</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>6ab4aa07f9207dae7518c35d4478291483d2609fb7a19f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>令和元年度補正予算（議案第９３号～第９７号）－令和元年１２月定例月議会</td>\n",
       "      <td>4</td>\n",
       "      <td>（自治体）予算</td>\n",
       "      <td>6</td>\n",
       "      <td>（自治体）補正予算</td>\n",
       "      <td>AA0180500</td>\n",
       "      <td>131</td>\n",
       "      <td>232297</td>\n",
       "      <td>23</td>\n",
       "      <td>愛知県</td>\n",
       "      <td>2297</td>\n",
       "      <td>豊明市</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://www.city.toyoake.lg.jp/secure/12291/R1...</td>\n",
       "      <td>2024-10-09 11:36:00</td>\n",
       "      <td></td>\n",
       "      <td>202411011</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>4542953af174acfdae8f06d4ca1829a9e1e739ffeea250...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1932 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  category category_name  \\\n",
       "0                          令和６年度一般会計補正予算（第１号）         4       （自治体）予算   \n",
       "1                      令和６年度一般会計補正予算説明資料（第１号）         4       （自治体）予算   \n",
       "2                             令和６年度４月補正予算（専決）         4       （自治体）予算   \n",
       "3                          令６年度　一般会計（第１号）補正予算         4       （自治体）予算   \n",
       "4                    令和６年度予算　４月１１日臨時議会　予算説明資料         4       （自治体）予算   \n",
       "...                                       ...       ...           ...   \n",
       "1927       令和２年度補正予算（議案第８２号～第８３号）－令和２年９月定例月議会         4       （自治体）予算   \n",
       "1928  令和２年度補正予算（議案第５５号・第７４号～第７５号）－令和２年６月定例月議会         4       （自治体）予算   \n",
       "1929       令和２年度補正予算（議案第３８号～第３９号）－令和２年定例会開会議会         4       （自治体）予算   \n",
       "1930       令和元年度補正予算（議案第２１号～第２９号）－令和２年３月定例月議会         4       （自治体）予算   \n",
       "1931      令和元年度補正予算（議案第９３号～第９７号）－令和元年１２月定例月議会         4       （自治体）予算   \n",
       "\n",
       "      sub_category sub_category_name    file_id number_of_pages    code  \\\n",
       "0                6         （自治体）補正予算  AA0178569              17  462187   \n",
       "1                6         （自治体）補正予算  AA0178570               2  462187   \n",
       "2                6         （自治体）補正予算  AA0178571               7  462195   \n",
       "3                6         （自治体）補正予算  AA0178572               8  462233   \n",
       "4                6         （自治体）補正予算  AA0178573               2  462233   \n",
       "...            ...               ...        ...             ...     ...   \n",
       "1927             6         （自治体）補正予算  AA0180496              44  232297   \n",
       "1928             6         （自治体）補正予算  AA0180497             136  232297   \n",
       "1929             6         （自治体）補正予算  AA0180498              30  232297   \n",
       "1930             6         （自治体）補正予算  AA0180499             193  232297   \n",
       "1931             6         （自治体）補正予算  AA0180500             131  232297   \n",
       "\n",
       "     affiliation_code affiliation organization_code organization  \\\n",
       "0                  46        鹿児島県              2187          霧島市   \n",
       "1                  46        鹿児島県              2187          霧島市   \n",
       "2                  46        鹿児島県              2195      いちき串木野市   \n",
       "3                  46        鹿児島県              2233         南九州市   \n",
       "4                  46        鹿児島県              2233         南九州市   \n",
       "...               ...         ...               ...          ...   \n",
       "1927               23         愛知県              2297          豊明市   \n",
       "1928               23         愛知県              2297          豊明市   \n",
       "1929               23         愛知県              2297          豊明市   \n",
       "1930               23         愛知県              2297          豊明市   \n",
       "1931               23         愛知県              2297          豊明市   \n",
       "\n",
       "      fiscal_year_start  fiscal_year_end  \\\n",
       "0                  2024             2024   \n",
       "1                  2024             2024   \n",
       "2                  2024             2024   \n",
       "3                  2024             2024   \n",
       "4                  2024             2024   \n",
       "...                 ...              ...   \n",
       "1927               2020             2020   \n",
       "1928               2020             2020   \n",
       "1929               2020             2020   \n",
       "1930               2019             2019   \n",
       "1931               2019             2019   \n",
       "\n",
       "                                             source_url        collected_at  \\\n",
       "0     https://www.city-kirishima.jp/zaisei/documents... 2024-03-30 15:55:00   \n",
       "1     https://www.city-kirishima.jp/zaisei/documents... 2024-03-30 15:55:00   \n",
       "2     https://www.city.ichikikushikino.lg.jp/zaisei1... 2024-03-30 15:55:00   \n",
       "3     https://www.city.minamikyushu.lg.jp/material/f... 2024-03-30 15:55:00   \n",
       "4     https://www.city.minamikyushu.lg.jp/material/f... 2024-03-30 15:55:00   \n",
       "...                                                 ...                 ...   \n",
       "1927  https://www.city.toyoake.lg.jp/secure/18340/R2... 2024-10-09 11:29:00   \n",
       "1928  https://www.city.toyoake.lg.jp/secure/18097/R2... 2024-10-09 11:31:00   \n",
       "1929  https://www.city.toyoake.lg.jp/secure/17736/R2... 2024-10-09 11:33:00   \n",
       "1930  https://www.city.toyoake.lg.jp/secure/16326/R2... 2024-10-09 11:34:00   \n",
       "1931  https://www.city.toyoake.lg.jp/secure/12291/R1... 2024-10-09 11:36:00   \n",
       "\n",
       "     modified_at  submit_id server_name  重複チェック URL判定 DL判定 DLエラー詳細 画像化  \\\n",
       "0                 202411011       Earth       0     0    0       -   0   \n",
       "1                 202411011       Earth       0     0    0       -   0   \n",
       "2                 202411011       Earth       0     0    0       -   0   \n",
       "3                 202411011       Earth       0     0    0       -   0   \n",
       "4                 202411011       Earth       0     0    0       -   0   \n",
       "...          ...        ...         ...     ...   ...  ...     ...  ..   \n",
       "1927              202411011       Earth       0     0    0       -   0   \n",
       "1928              202411011       Earth       0     0    0       -   0   \n",
       "1929              202411011       Earth       0     0    0       -   0   \n",
       "1930              202411011       Earth       0     0    0       -   0   \n",
       "1931              202411011       Earth       0     0    0       -   0   \n",
       "\n",
       "     画像化エラー詳細 テキスト解析 解析エラー詳細 OCR解析 OCRエラー詳細 GCP格納 GCPエラー詳細 画像格納 画像格納エラー詳細  \\\n",
       "0           -      0       -     -        -     0        -    0         -   \n",
       "1           -      0       -     -        -     0        -    0         -   \n",
       "2           -      0       -     -        -     0        -    0         -   \n",
       "3           -      0       -     -        -     0        -    0         -   \n",
       "4           -      0       -     -        -     0        -    0         -   \n",
       "...       ...    ...     ...   ...      ...   ...      ...  ...       ...   \n",
       "1927        -      0       -     -        -     0        -    0         -   \n",
       "1928        -      0       -     -        -     0        -    0         -   \n",
       "1929        -      0       -     -        -     0        -    0         -   \n",
       "1930        -      0       -     -        -     0        -    0         -   \n",
       "1931        -      0       -     -        -     0        -    0         -   \n",
       "\n",
       "     Elastic格納 Elasticエラー詳細                                               hash  \n",
       "0            0            -  0de6d82659dfe18a05c6d8e3f9103630c9312580028ea8...  \n",
       "1            0            -  3508cafe855bb9dbb39bf10fb255539433f86e073be545...  \n",
       "2            0            -  20e887d641164b796ac2d85b324b88bee1362e7f2521a8...  \n",
       "3            0            -  98853e537d38c8ff79710cdcd13c48da04b3ca12f6a6ed...  \n",
       "4            0            -  fad28051dd3cfca76faa2e4fb16019c34c3a0daf7b62a5...  \n",
       "...        ...          ...                                                ...  \n",
       "1927         0            -  a16637e927a41fcacaa02b3ccd6c363c879bf01cb273bc...  \n",
       "1928         0            -  0698ddce9919ce25a79eb2e43816561650d0a28a9b61ad...  \n",
       "1929         0            -  4ad9448d853f70e87c93e556f304356671ad54546dc772...  \n",
       "1930         0            -  6ab4aa07f9207dae7518c35d4478291483d2609fb7a19f...  \n",
       "1931         0            -  4542953af174acfdae8f06d4ca1829a9e1e739ffeea250...  \n",
       "\n",
       "[1932 rows x 36 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10.1.今回解析結果を出力\n",
    "report_name=str(inputdata.submit_id.min())+\"解析結果レポート.xlsx\"\n",
    "inputdata.set_index(\"file_id\").to_excel(path_teams+path_teams_report_folder+report_name)\n",
    "\n",
    "#10.2.last_submit_idへのデータ追加\n",
    "columns_to_write = ['file_id', 'source_url', 'category', 'sub_category', 'submit_id', 'server_name']\n",
    "\n",
    "last_submit_id_file_path =last_submit_id_folder+ inputdata['server_name'].iloc[0]+\".csv\"\n",
    "existing_data = pd.read_csv(last_submit_id_file_path)\n",
    "combined_data = pd.concat([existing_data,inputdata[columns_to_write]],\n",
    "                          ignore_index=True)\n",
    "\n",
    "combined_data.drop_duplicates(subset=['file_id'], keep='last', inplace=True)\n",
    "combined_data.to_csv(last_submit_id_file_path, index=False, columns=columns_to_write)\n",
    "\n",
    "#10.3.データフレームの保存先\n",
    "pickle_path=r\"../bunsyo/pickle/\"+str(inputdata.submit_id.min())+\"_\"+inputdata['server_name'].iloc[0]+\"_DataFrame.pkl\"\n",
    "inputdata.to_pickle(pickle_path)\n",
    "\n",
    "#end\n",
    "step_message = f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} {inputdata['submit_id'].min()} {inputdata['server_name'].iloc[0]}: All done.\"\n",
    "send_twilio_message(twilio_variables,step_message)\n",
    "print('データフレーム格納先：'+pickle_path)\n",
    "print(step_message)\n",
    "\n",
    "inputdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "2d0507b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Requirements出力\n",
    "##!pipreqsnb ./ --encoding=utf8 --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4745a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0a36e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc3327a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfdatatool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
